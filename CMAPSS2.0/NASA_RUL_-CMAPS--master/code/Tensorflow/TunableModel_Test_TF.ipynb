{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the DataHandlers. Test the CMAPSS DataHandler\n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D, LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define different types of Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_lambda_regularization = 0\n",
    "#l1_lambda_regularization = 0.2\n",
    "\n",
    "def RULmodel_LSTM(input_shape):\n",
    "    \"\"\"Define the RNN model\"\"\"\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    #model.add(Masking(mask_value=0, imput))\n",
    "    #model.add(LSTM(input_shape=input_shape, units=100, return_sequences=True, name='lstm1')))\n",
    "    model.add(LSTM(input_shape=input_shape, units=20, return_sequences=False, name='lstm2'))\n",
    "    model.add(Dense(10, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(input_shape, output_shape):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(None,input_shape), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=None, name=\"y\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_placeholders_rnn(num_features, sequence_length, output_shape):\n",
    "    X = tf.placeholder(tf.float32, shape=(None,sequence_length,num_features), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=None, name=\"y\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "#regularizers.l2(l2_lambda_regularization)\n",
    "def tf_model(X):\n",
    "    \n",
    "    l2_lambda_regularization = 0.20\n",
    "    l1_lambda_regularization = 0.10\n",
    "    \n",
    "    A1 = tf.layers.dense(X, 20, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False), \n",
    "                         kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(l1_lambda_regularization,l2_lambda_regularization), name=\"fc1\")\n",
    "    A2 = tf.layers.dense(A1, 20, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                         kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(l1_lambda_regularization,l2_lambda_regularization), name=\"fc2\")\n",
    "    y = tf.layers.dense(A2, 1, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(l1_lambda_regularization,l2_lambda_regularization), name=\"out\")\n",
    "    \n",
    "    return y\n",
    "\n",
    "def tf_lstm_model(X):\n",
    "    \n",
    "    l2_lambda_regularization = 0.20\n",
    "    l1_lambda_regularization = 0.10\n",
    "    \n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(20)\n",
    "    outputs,states = tf.contrib.rnn.static_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "    \n",
    "    A2 = tf.layers.dense(outputs[-1], 10, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                         kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(l1_lambda_regularization,l2_lambda_regularization), name=\"fc2\")\n",
    "    y = tf.layers.dense(A2, 1, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(l1_lambda_regularization,l2_lambda_regularization), name=\"out\")\n",
    "    return y \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_model_weights(model):\n",
    "\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights() # list of numpy arrays\n",
    "        \n",
    "        for weight in weights:\n",
    "        \n",
    "            print(weight.shape)\n",
    "            print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "\n",
    "dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "#dHandler_cmaps.load_data(verbose=1, cross_validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tunable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#min_max_scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_compiled_model(num_features, sequence_length, output_shape):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X, y = create_placeholders_rnn(num_features, sequence_length, output_shape)\n",
    "    \n",
    "    X = tf.unstack(X, axis=1)\n",
    "    \n",
    "    y_pred = tf_lstm_model(X)\n",
    "    cost = tf.losses.mean_squared_error(y, y_pred)\n",
    "    reg_cost = tf.losses.get_regularization_loss()\n",
    "    total_cost = cost + reg_cost\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001,beta1=0.5).minimize(total_cost)\n",
    "    \n",
    "    return {'X_placeholder':X, 'y_placeholder':y, 'y_pred':y_pred, 'cost':cost, 'total_cost':total_cost, 'optimizer':optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tModel = SequenceTunableModelRegression('ModelRUL_LSTM_1', None, lib_type='tensorflow', data_handler=dHandler_cmaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tModel.data_handler.sequence_length = 24\n",
    "#tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "tModel.data_handler.sequence_stride = 1\n",
    "tModel.data_handler.max_rul = 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Load Non sequenced data (unroll sequence into a single feature vector)\n",
    "\n",
    "# tModel.data_handler.data_scaler = None\n",
    "# tModel.data_scaler = min_max_scaler\n",
    "\n",
    "# tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "# #tModel.data_handler.print_data()\n",
    "# tModel.print_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "(512, 24, 14)\n",
      "24\n",
      "(512, 14)\n",
      "y_temp\n",
      "36\n",
      "(512, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#x_temp, y_temp = sklearn.utils.shuffle(tModel.X_train,tModel.y_train)\\nprint(\"x_temp\")\\nprint(len(X_batches))\\nprint(X_batches[0].shape)\\nprint(\"y_temp\")\\nprint(len(y_batches))\\nprint(y_batches[0].shape)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load sequenced data (do not unroll sequence into a single feature vector)\n",
    "\n",
    "tModel.data_handler.data_scaler = min_max_scaler\n",
    "tModel.data_scaler = None\n",
    "\n",
    "tModel.load_data(unroll=False, verbose=1, cross_validation_ratio=0)\n",
    "#tModel.data_handler.print_data()\n",
    "\n",
    "\n",
    "#tModel.print_data()\n",
    "\n",
    "X_batches, y_batches, total_batch = aux_functions.get_minibatches(tModel.X_train,tModel.y_train, 512)\n",
    "print(X_batches[0].shape)\n",
    "X_input = tf.unstack(X_batches[0], axis=1)\n",
    "print(len(X_input))\n",
    "print(X_input[0].shape)\n",
    "\n",
    "print(\"y_temp\")\n",
    "print(len(y_batches))\n",
    "print(y_batches[0].shape)\n",
    "\n",
    "\"\"\"\n",
    "#x_temp, y_temp = sklearn.utils.shuffle(tModel.X_train,tModel.y_train)\n",
    "print(\"x_temp\")\n",
    "print(len(X_batches))\n",
    "print(X_batches[0].shape)\n",
    "print(\"y_temp\")\n",
    "print(len(y_batches))\n",
    "print(y_batches[0].shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and test some Tunable Model functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512, 24, 14)\n",
      "[[[ 0.07831325 -0.26531502 -0.15057394 ... -0.16666667  0.2248062\n",
      "   -0.06766087]\n",
      "  [ 0.19277108 -0.44756922 -0.3679946  ... -0.33333333  0.20930233\n",
      "    0.22590445]\n",
      "  [-0.01807229 -0.24395029 -0.06076975 ... -0.33333333 -0.02325581\n",
      "    0.03148302]\n",
      "  ...\n",
      "  [-0.02409639 -0.33682145  0.06347063 ...  0.          0.10077519\n",
      "    0.05053853]\n",
      "  [-0.10240964 -0.32679311 -0.30452397 ...  0.         -0.08527132\n",
      "    0.0091135 ]\n",
      "  [-0.40963855 -0.06256813  0.03511141 ...  0.         -0.00775194\n",
      "   -0.27340514]]\n",
      "\n",
      " [[-0.08433735 -0.39524744  0.19513842 ...  0.          0.1627907\n",
      "    0.02982601]\n",
      "  [-0.22891566 -0.10355352 -0.16374072 ... -0.33333333  0.25581395\n",
      "   -0.11184756]\n",
      "  [-0.01204819 -0.06082407  0.14854828 ...  0.         -0.11627907\n",
      "   -0.20408727]\n",
      "  ...\n",
      "  [ 0.11445783  0.6529322   0.17994598 ...  0.16666667 -0.06976744\n",
      "   -0.23584645]\n",
      "  [ 0.1746988   0.22868978  0.1596894  ...  0.33333333 -0.42635659\n",
      "   -0.44904722]\n",
      "  [ 0.41566265  0.47721823  0.15226199 ...  0.33333333 -0.17829457\n",
      "   -0.46948357]]\n",
      "\n",
      " [[-0.38554217 -0.41966427 -0.47636732 ... -0.33333333  0.42635659\n",
      "    0.53438277]\n",
      "  [-0.06024096 -0.23915413 -0.27852802 ... -0.33333333  0.10077519\n",
      "    0.42612538]\n",
      "  [-0.03614458 -0.3677785  -0.38656313 ... -0.16666667  0.24031008\n",
      "    0.30046948]\n",
      "  ...\n",
      "  [-0.39156627 -0.43405276 -0.30688724 ... -0.33333333  0.11627907\n",
      "    0.53852527]\n",
      "  [-0.39759036 -0.59145411 -0.29642134 ... -0.5         0.02325581\n",
      "    0.36398785]\n",
      "  [-0.27710843 -0.64203183 -0.17083052 ... -0.5         0.08527132\n",
      "    0.14415907]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.53012048 -0.57575758 -0.38284943 ... -0.33333333  0.37984496\n",
      "    0.33664733]\n",
      "  [-0.58433735  0.02550687 -0.58474004 ... -0.66666667  0.58139535\n",
      "    0.48909141]\n",
      "  [-0.44578313 -0.40178766 -0.35111411 ... -0.5         0.11627907\n",
      "    0.25103563]\n",
      "  ...\n",
      "  [-0.52409639 -0.44844125 -0.32613099 ... -0.5         0.27131783\n",
      "    0.11295222]\n",
      "  [-0.58433735 -0.28319163 -0.34064821 ... -0.5         0.47286822\n",
      "    0.46893123]\n",
      "  [-0.3253012  -0.28711576 -0.55604321 ... -0.5         0.1627907\n",
      "    0.13532173]]\n",
      "\n",
      " [[-0.24698795 -0.31938086 -0.30519919 ... -0.33333333  0.24031008\n",
      "    0.17205192]\n",
      "  [-0.35542169 -0.32592108 -0.16340311 ... -0.33333333  0.19379845\n",
      "    0.24468379]\n",
      "  [ 0.03012048 -0.12666231 -0.42775152 ... -0.5         0.19379845\n",
      "    0.2645678 ]\n",
      "  ...\n",
      "  [-0.39156627 -0.60366252 -0.26671168 ... -0.33333333  0.17829457\n",
      "    0.14415907]\n",
      "  [-0.01204819 -0.32548507 -0.2744767  ... -0.16666667  0.19379845\n",
      "   -0.28969898]\n",
      "  [-0.42168675 -0.0324831  -0.53409858 ... -0.33333333  0.08527132\n",
      "    0.34161834]]\n",
      "\n",
      " [[-0.18674699 -0.15543928 -0.14517218 ...  0.          0.05426357\n",
      "    0.16597625]\n",
      "  [-0.06626506 -0.04294746 -0.05030385 ... -0.16666667 -0.20930233\n",
      "    0.23225628]\n",
      "  [-0.25903614  0.16372357  0.00911546 ... -0.16666667 -0.30232558\n",
      "    0.16459542]\n",
      "  ...\n",
      "  [ 0.21084337  0.0442555  -0.10871033 ...  0.         -0.36434109\n",
      "   -0.22728528]\n",
      "  [-0.1746988   0.04861565  0.17927076 ...  0.16666667 -0.2248062\n",
      "   -0.24827396]\n",
      "  [ 0.25903614  0.10529758  0.16374072 ...  0.         -0.10077519\n",
      "   -0.4084507 ]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4a4b64aff99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_minibatches_function_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maux_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minibatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/University_of_California/Research/Projects/ann_framework/tunable_model/tunable_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, verbose, learningRate_scheduler, tf_session, tensorboard, get_minibatches_function_handle, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A valid tensorflow session is needed to perform the training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_minibatches_function_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_minibatches_function_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University_of_California/Research/Projects/ann_framework/tunable_model/tunable_model.py\u001b[0m in \u001b[0;36mtrain_tf\u001b[0;34m(self, tf_session, get_minibatches_function_handle, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                                 \u001b[0mcost_tot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                                 \u001b[0mcost_reg_tot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "nFeatures = len(selected_features)\n",
    "\n",
    "#lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "\n",
    "# shape = len(selected_features)*tModel.data_handler.sequence_length\n",
    "# print(shape)\n",
    "\n",
    "shape = (nFeatures,tModel.data_handler.sequence_length)\n",
    "\n",
    "#modelRULSN = RULmodel_SN_5(shape)\n",
    "#modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "#model = get_compiled_model(shape, model_type='ann')\n",
    "#tModel.change_model('ModelRUL_SN_1', model, 'keras')\n",
    "\n",
    "model = tf_compiled_model(nFeatures,tModel.data_handler.sequence_length, 1)\n",
    "tModel.change_model('ModelRUL_LSTM_1', model, 'tensorflow')\n",
    "\n",
    "#tModel.print_data()\n",
    "\n",
    "#shape = (window_size, num_features)\n",
    "#model = get_compiled_model(shape, model_type='lstm')\n",
    "#tModel.change_model('ModelRUL_RNN_1', model, 'keras')\n",
    "\n",
    "#tModel.data_handler.data_scaler = min_max_scaler\n",
    "#tModel.data_scaler = min_max_scaler\n",
    "\n",
    "#print(\"Printing model weights\")\n",
    "#print_model_weights(tModel.model)\n",
    "\n",
    "tModel.epochs = 200\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "tModel.train_model(tf_session=sess, verbose=1, get_minibatches_function_handle=aux_functions.get_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tModel.evaluate_model(['rhs', 'rmse'], round=2, tf_session=sess)\n",
    "print(\"scores\")\n",
    "\n",
    "cScores = tModel.scores\n",
    "#rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.train_time\n",
    "\n",
    "i = range(1,len(tModel.y_test)+1)\n",
    "\n",
    "\n",
    "for i, rul_prediction, rul_prediction_rounded, true_rul in zip(i, np.ravel(tModel.y_predicted), tModel.y_predicted_rounded, np.ravel(tModel.y_test)):\n",
    "    print('Engine {}, Predicted RUL {}, Rounded RUL {}, Real RUL {}'.format(i, rul_prediction, \n",
    "                                                                    rul_prediction_rounded, \n",
    "                                                                    true_rul))\n",
    "\n",
    "print(cScores)\n",
    "#print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
