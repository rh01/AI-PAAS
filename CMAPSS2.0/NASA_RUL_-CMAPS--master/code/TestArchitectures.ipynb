{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the C-MAPPS benchmark. Test different MLP architectures. \n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "#sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression\n",
    "from ann_framework import aux_functions\n",
    "\n",
    "#import custom_scores\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.layers import LSTM, CuDNNLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define architectures\n",
    "\n",
    "Define each one of the different architectures to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()  #Clear the previous tensorflow graph\n",
    "\n",
    "l2_lambda_regularization = 0.20\n",
    "l1_lambda_regularization = 0.20\n",
    "\n",
    "def RULmodel_LSTM(input_shape):\n",
    "    \"\"\"Define the RNN model\"\"\"\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    #model.add(Masking(mask_value=0, imput))\n",
    "    #model.add(LSTM(input_shape=input_shape, units=100, return_sequences=True, name='lstm1')))\n",
    "    model.add(CuDNNLSTM(input_shape=input_shape, units=20, return_sequences=False, name='lstm2'))\n",
    "    model.add(Dense(10, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_5(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(model_def, shape, model_type='lstm'):\n",
    "\n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0, beta_1=0.5)\n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "\n",
    "    if model_type=='ann':\n",
    "        model = model_def(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    elif model_type=='lstm':\n",
    "        model = RULmodel_LSTM(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the usable models for this notebook\n",
    "\n",
    "#models = {'shallow-20':RULmodel_SN_5,'rnn-20-10':RULmodel_LSTM}\n",
    "models = {'shallow-20':RULmodel_SN_5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 128\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features, max_rul, \n",
    "                                  window_size, window_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "\n",
    "#Create and compile the models\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*window_size\n",
    "shapeLSTM = (window_size,nFeatures)\n",
    "model = get_compiled_model(models['shallow-20'], shapeSN, model_type='ann')\n",
    "\n",
    "tModel = SequenceTunableModelRegression('mlpnn', model, lib_type='keras', data_handler=dHandler_cmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for the first time\n",
      "Loading data for dataset 1 with window_size of 30, stride of 1 and maxRUL of 128. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(17731, 30, 14)\n",
      "(17731, 1)\n",
      "Testing data (X, y)\n",
      "(100, 30, 14)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.42635659\n",
      "    0.44932339]\n",
      "  [-0.43373494 -0.09396119 -0.29473329 ... -0.33333333  0.33333333\n",
      "    0.46202706]\n",
      "  [-0.31325301 -0.26095487 -0.25894666 ... -0.66666667  0.25581395\n",
      "    0.24275062]\n",
      "  ...\n",
      "  [-0.31325301 -0.48550251 -0.43011479 ... -0.66666667  0.34883721\n",
      "    0.07677437]\n",
      "  [-0.57831325 -0.39873556 -0.36731938 ... -0.16666667  0.2248062\n",
      "    0.28555648]\n",
      "  [-0.40361446 -0.01983867 -0.53308575 ... -0.66666667  0.41085271\n",
      "    0.42723005]]\n",
      "\n",
      " [[-0.43373494 -0.09396119 -0.29473329 ... -0.33333333  0.33333333\n",
      "    0.46202706]\n",
      "  [-0.31325301 -0.26095487 -0.25894666 ... -0.66666667  0.25581395\n",
      "    0.24275062]\n",
      "  [-0.31325301 -0.48768258 -0.33760972 ... -0.33333333  0.14728682\n",
      "    0.32477216]\n",
      "  ...\n",
      "  [-0.57831325 -0.39873556 -0.36731938 ... -0.16666667  0.2248062\n",
      "    0.28555648]\n",
      "  [-0.40361446 -0.01983867 -0.53308575 ... -0.66666667  0.41085271\n",
      "    0.42723005]\n",
      "  [-0.51204819 -0.42707652 -0.50540176 ... -0.33333333  0.24031008\n",
      "    0.21817178]]\n",
      "\n",
      " [[-0.31325301 -0.26095487 -0.25894666 ... -0.66666667  0.25581395\n",
      "    0.24275062]\n",
      "  [-0.31325301 -0.48768258 -0.33760972 ... -0.33333333  0.14728682\n",
      "    0.32477216]\n",
      "  [-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.17829457\n",
      "    0.40900304]\n",
      "  ...\n",
      "  [-0.40361446 -0.01983867 -0.53308575 ... -0.66666667  0.41085271\n",
      "    0.42723005]\n",
      "  [-0.51204819 -0.42707652 -0.50540176 ... -0.33333333  0.24031008\n",
      "    0.21817178]\n",
      "  [-0.3253012  -0.11314585 -0.38858879 ... -0.33333333  0.36434109\n",
      "    0.67274234]]\n",
      "\n",
      " [[-0.31325301 -0.48768258 -0.33760972 ... -0.33333333  0.14728682\n",
      "    0.32477216]\n",
      "  [-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.17829457\n",
      "    0.40900304]\n",
      "  [-0.46385542 -0.41443209 -0.45577313 ... -0.5         0.30232558\n",
      "    0.30544049]\n",
      "  ...\n",
      "  [-0.51204819 -0.42707652 -0.50540176 ... -0.33333333  0.24031008\n",
      "    0.21817178]\n",
      "  [-0.3253012  -0.11314585 -0.38858879 ... -0.33333333  0.36434109\n",
      "    0.67274234]\n",
      "  [-0.09638554 -0.24307826 -0.31870358 ... -0.33333333  0.06976744\n",
      "    0.2604253 ]]\n",
      "\n",
      " [[-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.17829457\n",
      "    0.40900304]\n",
      "  [-0.46385542 -0.41443209 -0.45577313 ... -0.5         0.30232558\n",
      "    0.30544049]\n",
      "  [-0.23493976 -0.07216045 -0.47602971 ... -0.33333333  0.48837209\n",
      "    0.334438  ]\n",
      "  ...\n",
      "  [-0.3253012  -0.11314585 -0.38858879 ... -0.33333333  0.36434109\n",
      "    0.67274234]\n",
      "  [-0.09638554 -0.24307826 -0.31870358 ... -0.33333333  0.06976744\n",
      "    0.2604253 ]\n",
      "  [-0.19879518 -0.54523654 -0.38453747 ... -0.33333333  0.03875969\n",
      "    0.14609224]]]\n",
      "[[128.]\n",
      " [128.]\n",
      " [128.]\n",
      " [128.]\n",
      " [128.]]\n",
      "Testing data (X, y)\n",
      "[[[-0.69879518 -0.24089819 -0.55536799 ... -0.16666667  0.36434109\n",
      "    0.37365369]\n",
      "  [-0.24698795 -0.30673643 -0.35550304 ... -0.16666667  0.45736434\n",
      "    0.44269539]\n",
      "  [-0.25903614 -0.42969261 -0.1839973  ... -0.5         0.33333333\n",
      "    0.32421983]\n",
      "  ...\n",
      "  [-0.55421687 -0.29758012 -0.46455098 ... -0.33333333  0.36434109\n",
      "    0.29218448]\n",
      "  [-0.04819277 -0.35993024 -0.3679946  ... -0.5         0.47286822\n",
      "    0.41590721]\n",
      "  [-0.1746988  -0.55613691 -0.4375422  ... -0.16666667  0.03875969\n",
      "    0.27312897]]\n",
      "\n",
      " [[-0.09036145 -0.21037715 -0.37744767 ... -0.16666667 -0.02325581\n",
      "   -0.01877934]\n",
      "  [-0.3313253  -0.14192283 -0.31971641 ...  0.          0.1627907\n",
      "    0.35156034]\n",
      "  [-0.25903614 -0.37039459  0.027684   ... -0.16666667  0.14728682\n",
      "   -0.02430268]\n",
      "  ...\n",
      "  [-0.01204819 -0.27883148 -0.2916948  ... -0.33333333  0.14728682\n",
      "    0.11101906]\n",
      "  [-0.13855422 -0.27316329  0.00303849 ... -0.33333333  0.31782946\n",
      "    0.09803922]\n",
      "  [-0.19277108 -0.32199695 -0.03511141 ... -0.5         0.03875969\n",
      "    0.01518917]]\n",
      "\n",
      " [[-0.0060241  -0.22127752 -0.10634706 ... -0.33333333  0.05426357\n",
      "   -0.02927368]\n",
      "  [-0.24698795  0.10137345 -0.07191087 ...  0.          0.31782946\n",
      "   -0.01657001]\n",
      "  [-0.09638554  0.04251145 -0.06515868 ... -0.16666667  0.24031008\n",
      "   -0.09306821]\n",
      "  ...\n",
      "  [ 0.11445783 -0.15195117  0.03072248 ...  0.16666667 -0.1627907\n",
      "   -0.05799503]\n",
      "  [ 0.22289157 -0.23261391  0.02464551 ...  0.         -0.34883721\n",
      "   -0.08091687]\n",
      "  [ 0.0060241  -0.18421626  0.23700203 ...  0.16666667  0.2248062\n",
      "    0.04888152]]\n",
      "\n",
      " [[-0.25301205 -0.00414214 -0.13605672 ... -0.66666667  0.08527132\n",
      "    0.21071527]\n",
      "  [ 0.19277108 -0.47721823 -0.24240378 ... -0.16666667  0.20930233\n",
      "    0.20822977]\n",
      "  [ 0.0060241  -0.07041639 -0.17420662 ...  0.          0.05426357\n",
      "    0.30019332]\n",
      "  ...\n",
      "  [-0.01204819 -0.22040549 -0.19277515 ... -0.33333333  0.13178295\n",
      "   -0.01077051]\n",
      "  [-0.11445783 -0.04207543 -0.12356516 ...  0.16666667 -0.17829457\n",
      "    0.04473902]\n",
      "  [-0.05421687  0.02419882 -0.16846725 ...  0.16666667 -0.31782946\n",
      "    0.004971  ]]\n",
      "\n",
      " [[-0.1746988   0.06256813 -0.10263336 ...  0.         -0.06976744\n",
      "    0.09500138]\n",
      "  [-0.27710843 -0.42489645 -0.32680621 ... -0.16666667 -0.06976744\n",
      "    0.11571389]\n",
      "  [ 0.14457831 -0.28667975 -0.34469953 ...  0.         -0.13178295\n",
      "   -0.10411489]\n",
      "  ...\n",
      "  [-0.09638554 -0.06692828 -0.09250506 ... -0.16666667  0.10077519\n",
      "   -0.08312621]\n",
      "  [-0.09036145 -0.03902333  0.11208643 ...  0.         -0.1627907\n",
      "    0.12510356]\n",
      "  [-0.36144578 -0.17593198  0.25286968 ...  0.         -0.05426357\n",
      "    0.42916321]]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n"
     ]
    }
   ],
   "source": [
    "#For LSTM\n",
    "tModel.data_handler.data_scaler = min_max_scaler\n",
    "tModel.data_scaler = None\n",
    "\n",
    "#For ANN\n",
    "#tModel.data_handler.data_scaler = min_max_scaler\n",
    "#tModel.data_scaler = min_max_scaler\n",
    "\n",
    "tModel.data_handler.sequence_length = 30\n",
    "#tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "tModel.data_handler.sequence_stride = 1\n",
    "tModel.data_handler.max_rul = 128\n",
    "\n",
    "tModel.load_data(unroll=False, verbose=1, cross_validation_ratio=0)\n",
    "tModel.print_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model shallow-20\n",
      "Computing for dataset 1\n",
      "Reloading data due to parameter change\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 396us/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 758us/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 852us/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 698us/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 821us/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "Results for model shallow-20\n",
      "DescribeResult(nobs=10, minmax=(array([15.91917083]), array([17.67116295])), mean=array([16.78943174]), variance=array([0.37331329]), skewness=array([0.23510294]), kurtosis=array([-1.18510939]))\n",
      "DescribeResult(nobs=10, minmax=(array([5.94056037]), array([10.04350626])), mean=array([7.63331569]), variance=array([2.07192254]), skewness=array([0.64582011]), kurtosis=array([-1.09664502]))\n",
      "DescribeResult(nobs=10, minmax=(array([19.991515]), array([21.508875])), mean=array([20.8381423]), variance=array([0.3510754]), skewness=array([-0.27872828]), kurtosis=array([-1.41885278]))\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "tModel.epochs = 100\n",
    "lrate = LearningRateScheduler(aux_functions.step_decay)\n",
    "num_features = len(selected_features)\n",
    "\n",
    "windowSize = 30\n",
    "windowStride = 1\n",
    "constRul = 140\n",
    "\n",
    "file = open(\"results/MLP/ResultsDatasets_1_test.csv\", \"w\")\n",
    "csvfile = csv.writer(file, lineterminator='\\n')\n",
    "\n",
    "for key, model_def in models.items():\n",
    "  \n",
    "    print(\"For model \"+str(key))\n",
    "    #file.write(\"For model \"+str(key)+'\\n\\n')\n",
    "  \n",
    "    for i in range(1,2):\n",
    "\n",
    "        dataset = i\n",
    "        print(\"Computing for dataset \"+str(i))\n",
    "        #file.write(\"Computing for dataset \"+str(i)+'\\n\\n')\n",
    "      \n",
    "        tempScoresRMSE = np.zeros((iterations,1))\n",
    "        tempScoresRHS = np.zeros((iterations,1))\n",
    "        tempTime = np.zeros((iterations,1))\n",
    "      \n",
    "        input_shape = windowSize*num_features #For simple ANN\n",
    "      \n",
    "        tModel.data_handler.change_dataset(i)\n",
    "        tModel.data_handler.sequence_length = windowSize\n",
    "        tModel.data_handler.sequence_stride = windowStride\n",
    "        tModel.data_handler.max_rul = constRul\n",
    "        tModel.load_data(unroll=True, verbose=0, cross_validation_ratio=0)\n",
    "        #tModel.print_data()\n",
    "\n",
    "        for j in range(iterations):\n",
    "\n",
    "            #Model needs to be recompiled everytime since they are different runs so weights should be reinit\n",
    "            model = get_compiled_model(model_def, input_shape, model_type='ann')\n",
    "\n",
    "            tModel.change_model(key, model, 'keras')\n",
    "            tModel.train_model(learningRate_scheduler=lrate, verbose=0)\n",
    "            tModel.evaluate_model(['rhs', 'rmse'], round=2)\n",
    "            #print(\"scores\")\n",
    "          \n",
    "            #print(j)\n",
    "\n",
    "            cScores = tModel.scores\n",
    "            rmse = math.sqrt(cScores['score_1'])\n",
    "            rmse2 = cScores['rmse']\n",
    "            rhs = cScores['rhs']\n",
    "            time = tModel.train_time\n",
    "          \n",
    "            tempScoresRMSE[j] = rmse2\n",
    "            tempScoresRHS[j] = rhs\n",
    "            tempTime[j] = time\n",
    "\n",
    "        print(\"Results for model \" + key)\n",
    "  \n",
    "        print(stats.describe(tempScoresRMSE))\n",
    "        print(stats.describe(tempScoresRHS))\n",
    "        print(stats.describe(tempTime))\n",
    "          \n",
    "        tempScoresRMSE = np.reshape(tempScoresRMSE, (iterations,))\n",
    "        tempScoresRHS = np.reshape(tempScoresRHS, (iterations,))\n",
    "        tempTime = np.reshape(tempTime, (iterations,))\n",
    "        csvfile.writerow(tempScoresRMSE)\n",
    "        csvfile.writerow(tempScoresRHS)\n",
    "        csvfile.writerow(tempTime)\n",
    "        \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on all Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 20)                8420      \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 8,861\n",
      "Trainable params: 8,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Generating statistics for model shallow-20\n",
      "Working on dataset 1\n",
      "420\n",
      "Reloading data due to parameter change\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "training without cv\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "Results for model shallow-20\n",
      "DescribeResult(nobs=2, minmax=(array([16.31073266]), array([16.43045952])), mean=array([16.37059609]), variance=array([0.00716726]), skewness=array([0.]), kurtosis=array([-2.]))\n",
      "DescribeResult(nobs=2, minmax=(array([6.64598616]), array([6.80945415])), mean=array([6.72772015]), variance=array([0.01336089]), skewness=array([-1.62823075e-14]), kurtosis=array([-2.]))\n",
      "DescribeResult(nobs=2, minmax=(array([30.616317]), array([32.516059])), mean=array([31.566188]), variance=array([1.80450983]), skewness=array([0.]), kurtosis=array([-2.]))\n"
     ]
    }
   ],
   "source": [
    "datasets = [1,2,3,4]\n",
    "iterations = 2\n",
    "tModel.epochs = 150\n",
    "lrate = LearningRateScheduler(aux_functions.step_decay)\n",
    "scores ={1:[], 2:[], 3:[], 4:[]}\n",
    "window_sizes = {1:30,2:20,3:30,4:18}\n",
    "strides = {1:1,2:2,3:1,4:2}\n",
    "max_ruls = {1:140, 2:134, 3:128, 4:134}\n",
    "num_features = len(selected_features)\n",
    "\n",
    "input_shape = None\n",
    "\n",
    "#For each model\n",
    "for key, model_def in models.items():\n",
    "    file = open(\"results/MLP/ResultsDatasets_1_test\"+key+\".csv\", \"w\")\n",
    "    csvfile = csv.writer(file, lineterminator='\\n')\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    print(\"Generating statistics for model \" + key)\n",
    "\n",
    "    #For each dataset\n",
    "    for i in range(1,2):\n",
    "        \n",
    "        print(\"Working on dataset \" + str(i))\n",
    "        \n",
    "        tempScoresRMSE = np.zeros((iterations,1))\n",
    "        tempScoresRHS = np.zeros((iterations,1))\n",
    "        tempTime = np.zeros((iterations,1))\n",
    "        \n",
    "        input_shape = window_sizes[i]*num_features #For simple ANN\n",
    "        #input_shape = (window_sizes[i],num_features) #For RNN\n",
    "        \n",
    "        print(input_shape)\n",
    "        \n",
    "        tModel.data_handler.change_dataset(i)\n",
    "        tModel.data_handler.sequence_length = window_sizes[i]\n",
    "        tModel.data_handler.sequence_stride = strides[i]\n",
    "        tModel.data_handler.max_rul = max_ruls[i]\n",
    "        tModel.load_data(unroll=True, verbose=0, cross_validation_ratio=0)\n",
    "        #tModel.print_data()\n",
    "        \n",
    "        #tModel.print_data()\n",
    "        \n",
    "        for j in range(iterations):\n",
    "\n",
    "            #Model needs to be recompiled everytime since they are different runs so weights should be reinit\n",
    "            model = get_compiled_model(model_def, input_shape, model_type='ann')\n",
    "\n",
    "            tModel.change_model(key, model, 'keras')\n",
    "            tModel.train_model(learningRate_scheduler=lrate, verbose=0)\n",
    "            tModel.evaluate_model(['rhs', 'rmse'], round=2)\n",
    "            #print(\"scores\")\n",
    "            \n",
    "            #print(j)\n",
    "\n",
    "            cScores = tModel.scores\n",
    "            rmse = math.sqrt(cScores['score_1'])\n",
    "            rmse2 = cScores['rmse']\n",
    "            rhs = cScores['rhs']\n",
    "            time = tModel.train_time\n",
    "            \n",
    "            tempScoresRMSE[j] = rmse2\n",
    "            tempScoresRHS[j] = rhs\n",
    "            tempTime[j] = time\n",
    "            \n",
    "        print(\"Results for model \" + key)\n",
    "    \n",
    "        print(stats.describe(tempScoresRMSE))\n",
    "        print(stats.describe(tempScoresRHS))\n",
    "        print(stats.describe(tempTime))\n",
    "            \n",
    "        tempScoresRMSE = np.reshape(tempScoresRMSE, (iterations,))\n",
    "        tempScoresRHS = np.reshape(tempScoresRHS, (iterations,))\n",
    "        tempTime = np.reshape(tempTime, (iterations,))\n",
    "        csvfile.writerow(tempScoresRMSE)\n",
    "        csvfile.writerow(tempScoresRHS)\n",
    "        csvfile.writerow(tempTime)\n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
