{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.models import model_from_json, clone_model\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression\n",
    "from ann_framework import aux_functions\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define different the model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RULmodel_SN_1(input_shape):\n",
    "    \n",
    "    l2_lambda_regularization = 0.20\n",
    "    l1_lambda_regularization = 0.10\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=l1_lambda_regularization, l2=l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=l1_lambda_regularization, l2=l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(shape, model_type='ann'):\n",
    "    \n",
    "    K.clear_session()  #Clear the previous tensorflow graph\n",
    "    \n",
    "    #To test the model without randomness\n",
    "\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001,beta_1=0.5)\n",
    "    \n",
    "    #optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    \n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "\n",
    "    if model_type=='ann':\n",
    "        model = RULmodel_SN_1(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    elif model_type=='lstm':\n",
    "        model = RULmodel_LSTM(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "\n",
    "dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "#dHandler_cmaps.load_data(verbose=1, cross_validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dataset 2\n",
      "Iteration 1\n",
      "Loading data for the first time\n",
      "Reloading data due to parameter change\n",
      "Loading data for dataset 2 with window_size of 17, stride of 1 and maxRUL of 139. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "training without cv\n",
      "Epoch 1/200\n",
      "49599/49599 [==============================] - 1s 19us/step - loss: 5841.2071 - mean_squared_error: 5786.4373\n",
      "Epoch 2/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 2381.8143 - mean_squared_error: 2323.4577\n",
      "Epoch 3/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 2355.4941 - mean_squared_error: 2298.4184\n",
      "Epoch 4/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 2321.4350 - mean_squared_error: 2264.3624\n",
      "Epoch 5/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 2283.8800 - mean_squared_error: 2226.1436\n",
      "Epoch 6/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 2243.5150 - mean_squared_error: 2184.8203\n",
      "Epoch 7/200\n",
      "49599/49599 [==============================] - 1s 15us/step - loss: 2190.1435 - mean_squared_error: 2129.8590\n",
      "Epoch 8/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 2127.5375 - mean_squared_error: 2065.3893\n",
      "Epoch 9/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 2042.8323 - mean_squared_error: 1978.2535\n",
      "Epoch 10/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 1936.9487 - mean_squared_error: 1869.0193\n",
      "Epoch 11/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 1806.1472 - mean_squared_error: 1734.1056\n",
      "Epoch 12/200\n",
      "49599/49599 [==============================] - 1s 10us/step - loss: 1658.3059 - mean_squared_error: 1581.1622\n",
      "Epoch 13/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 1505.0159 - mean_squared_error: 1422.9870\n",
      "Epoch 14/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 1358.1820 - mean_squared_error: 1271.6335\n",
      "Epoch 15/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 1249.2395 - mean_squared_error: 1158.6236\n",
      "Epoch 16/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 1152.0709 - mean_squared_error: 1058.3299\n",
      "Epoch 17/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 1094.7534 - mean_squared_error: 998.6462\n",
      "Epoch 18/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 1056.4113 - mean_squared_error: 958.6974\n",
      "Epoch 19/200\n",
      "49599/49599 [==============================] - 1s 10us/step - loss: 1020.7068 - mean_squared_error: 921.9655\n",
      "Epoch 20/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 999.9946 - mean_squared_error: 900.6917\n",
      "Epoch 21/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 987.2034 - mean_squared_error: 887.6027\n",
      "Epoch 22/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 977.3923 - mean_squared_error: 877.5986\n",
      "Epoch 23/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 963.2776 - mean_squared_error: 863.4515\n",
      "Epoch 24/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 960.2141 - mean_squared_error: 860.4448\n",
      "Epoch 25/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 952.8533 - mean_squared_error: 853.2316\n",
      "Epoch 26/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 946.1359 - mean_squared_error: 846.7261\n",
      "Epoch 27/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 946.7334 - mean_squared_error: 847.5925\n",
      "Epoch 28/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 944.9802 - mean_squared_error: 846.1866\n",
      "Epoch 29/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 943.2763 - mean_squared_error: 844.7843\n",
      "Epoch 30/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 942.0374 - mean_squared_error: 843.9091\n",
      "Epoch 31/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 935.0302 - mean_squared_error: 837.2373\n",
      "Epoch 32/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 935.6785 - mean_squared_error: 838.2419\n",
      "Epoch 33/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 934.4268 - mean_squared_error: 837.3751\n",
      "Epoch 34/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 938.9191 - mean_squared_error: 842.2789\n",
      "Epoch 35/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 930.3110 - mean_squared_error: 834.0485\n",
      "Epoch 36/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 935.0329 - mean_squared_error: 839.2023\n",
      "Epoch 37/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 926.5897 - mean_squared_error: 831.1288\n",
      "Epoch 38/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 923.4119 - mean_squared_error: 828.3674\n",
      "Epoch 39/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 924.4545 - mean_squared_error: 829.7938\n",
      "Epoch 40/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 924.9156 - mean_squared_error: 830.6551\n",
      "Epoch 41/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 924.1668 - mean_squared_error: 830.2850\n",
      "Epoch 42/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 924.5909 - mean_squared_error: 831.0710\n",
      "Epoch 43/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 920.2091 - mean_squared_error: 827.0485: 0s - loss: 921.1231 - mean_squared_err\n",
      "Epoch 44/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 918.1504 - mean_squared_error: 825.3690\n",
      "Epoch 45/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 918.8064 - mean_squared_error: 826.3705\n",
      "Epoch 46/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 920.4088 - mean_squared_error: 828.3676\n",
      "Epoch 47/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 920.6617 - mean_squared_error: 828.9778\n",
      "Epoch 48/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 918.2952 - mean_squared_error: 826.9301\n",
      "Epoch 49/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 912.9616 - mean_squared_error: 821.9477\n",
      "Epoch 50/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 913.6883 - mean_squared_error: 823.0208\n",
      "Epoch 51/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 916.4534 - mean_squared_error: 826.1543\n",
      "Epoch 52/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 908.8490 - mean_squared_error: 818.8764\n",
      "Epoch 53/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 909.7856 - mean_squared_error: 820.1448\n",
      "Epoch 54/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 911.8616 - mean_squared_error: 822.6208\n",
      "Epoch 55/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 909.6154 - mean_squared_error: 820.7095\n",
      "Epoch 56/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 906.8747 - mean_squared_error: 818.3051\n",
      "Epoch 57/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 909.4675 - mean_squared_error: 821.2457\n",
      "Epoch 58/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 908.3196 - mean_squared_error: 820.4489\n",
      "Epoch 59/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 906.1623 - mean_squared_error: 818.6379\n",
      "Epoch 60/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 911.6912 - mean_squared_error: 824.5187\n",
      "Epoch 61/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 907.3454 - mean_squared_error: 820.5022\n",
      "Epoch 62/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 901.2495 - mean_squared_error: 814.7376\n",
      "Epoch 63/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 901.3175 - mean_squared_error: 815.1076\n",
      "Epoch 64/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 902.3397 - mean_squared_error: 816.4941\n",
      "Epoch 65/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 899.5232 - mean_squared_error: 813.9905\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49599/49599 [==============================] - 0s 7us/step - loss: 907.3118 - mean_squared_error: 822.1058\n",
      "Epoch 67/200\n",
      "49599/49599 [==============================] - 0s 10us/step - loss: 909.1481 - mean_squared_error: 824.2821\n",
      "Epoch 68/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 900.7474 - mean_squared_error: 816.1663\n",
      "Epoch 69/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 897.3076 - mean_squared_error: 813.0164\n",
      "Epoch 70/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 897.0692 - mean_squared_error: 813.0998\n",
      "Epoch 71/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 896.0657 - mean_squared_error: 812.4116\n",
      "Epoch 72/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 900.8913 - mean_squared_error: 817.5157\n",
      "Epoch 73/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 895.5451 - mean_squared_error: 812.5121\n",
      "Epoch 74/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 895.6464 - mean_squared_error: 812.8901\n",
      "Epoch 75/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 898.9400 - mean_squared_error: 816.4847\n",
      "Epoch 76/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 896.8380 - mean_squared_error: 814.6750\n",
      "Epoch 77/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 894.2373 - mean_squared_error: 812.3497\n",
      "Epoch 78/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 895.1774 - mean_squared_error: 813.6041\n",
      "Epoch 79/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 895.4318 - mean_squared_error: 814.1470\n",
      "Epoch 80/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 891.8113 - mean_squared_error: 810.7977\n",
      "Epoch 81/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 888.7512 - mean_squared_error: 808.0061\n",
      "Epoch 82/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 891.4376 - mean_squared_error: 810.9734\n",
      "Epoch 83/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 888.1501 - mean_squared_error: 807.9749\n",
      "Epoch 84/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 892.0304 - mean_squared_error: 812.1592\n",
      "Epoch 85/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 890.0050 - mean_squared_error: 810.3899\n",
      "Epoch 86/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 889.6867 - mean_squared_error: 810.3517\n",
      "Epoch 87/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 891.4971 - mean_squared_error: 812.4416\n",
      "Epoch 88/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 886.2846 - mean_squared_error: 807.4891\n",
      "Epoch 89/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 887.8117 - mean_squared_error: 809.2732\n",
      "Epoch 90/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 890.5417 - mean_squared_error: 812.2723\n",
      "Epoch 91/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 887.3043 - mean_squared_error: 809.3218\n",
      "Epoch 92/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 882.7411 - mean_squared_error: 804.9920\n",
      "Epoch 93/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 888.9690 - mean_squared_error: 811.4897\n",
      "Epoch 94/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 887.2113 - mean_squared_error: 809.9763\n",
      "Epoch 95/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 884.6591 - mean_squared_error: 807.6409\n",
      "Epoch 96/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 883.4535 - mean_squared_error: 806.6924\n",
      "Epoch 97/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 880.8040 - mean_squared_error: 804.2707\n",
      "Epoch 98/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 882.1414 - mean_squared_error: 805.8410\n",
      "Epoch 99/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 879.7006 - mean_squared_error: 803.6394\n",
      "Epoch 100/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 883.9253 - mean_squared_error: 808.1127\n",
      "Epoch 101/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 876.5170 - mean_squared_error: 800.9532\n",
      "Epoch 102/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 881.6098 - mean_squared_error: 806.2568\n",
      "Epoch 103/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 881.4508 - mean_squared_error: 806.3305\n",
      "Epoch 104/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 880.9613 - mean_squared_error: 806.0994\n",
      "Epoch 105/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 877.6310 - mean_squared_error: 802.9889\n",
      "Epoch 106/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 875.4080 - mean_squared_error: 800.9823\n",
      "Epoch 107/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 877.9160 - mean_squared_error: 803.7101\n",
      "Epoch 108/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 881.2222 - mean_squared_error: 807.2611\n",
      "Epoch 109/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 875.0696 - mean_squared_error: 801.2997\n",
      "Epoch 110/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 879.8941 - mean_squared_error: 806.3707\n",
      "Epoch 111/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 876.0799 - mean_squared_error: 802.7647\n",
      "Epoch 112/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 875.5870 - mean_squared_error: 802.4952\n",
      "Epoch 113/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 874.8847 - mean_squared_error: 802.0104\n",
      "Epoch 114/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 873.2437 - mean_squared_error: 800.5587\n",
      "Epoch 115/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 873.5134 - mean_squared_error: 801.0366\n",
      "Epoch 116/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 870.4936 - mean_squared_error: 798.2249\n",
      "Epoch 117/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 871.6030 - mean_squared_error: 799.5449\n",
      "Epoch 118/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 871.8370 - mean_squared_error: 800.0001\n",
      "Epoch 119/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 876.8725 - mean_squared_error: 805.2552\n",
      "Epoch 120/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 872.4875 - mean_squared_error: 801.0729\n",
      "Epoch 121/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 868.3262 - mean_squared_error: 797.1009\n",
      "Epoch 122/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 870.6512 - mean_squared_error: 799.6135\n",
      "Epoch 123/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 869.7161 - mean_squared_error: 798.8729\n",
      "Epoch 124/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 868.4511 - mean_squared_error: 797.8307\n",
      "Epoch 125/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 871.4773 - mean_squared_error: 801.0358\n",
      "Epoch 126/200\n",
      "49599/49599 [==============================] - 0s 8us/step - loss: 870.3344 - mean_squared_error: 800.0849\n",
      "Epoch 127/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 871.3478 - mean_squared_error: 801.2959\n",
      "Epoch 128/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 863.8981 - mean_squared_error: 794.0095\n",
      "Epoch 129/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 866.4422 - mean_squared_error: 796.7444\n",
      "Epoch 130/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 866.9964 - mean_squared_error: 797.4906\n",
      "Epoch 131/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 867.7238 - mean_squared_error: 798.4001\n",
      "Epoch 132/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 869.7782 - mean_squared_error: 800.6466\n",
      "Epoch 133/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 864.5985 - mean_squared_error: 795.6386\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49599/49599 [==============================] - 0s 7us/step - loss: 868.5956 - mean_squared_error: 799.8294\n",
      "Epoch 135/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 861.7372 - mean_squared_error: 793.1236\n",
      "Epoch 136/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 861.6162 - mean_squared_error: 793.2142\n",
      "Epoch 137/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 864.1349 - mean_squared_error: 795.8942\n",
      "Epoch 138/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 860.9745 - mean_squared_error: 792.8851\n",
      "Epoch 139/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 862.5823 - mean_squared_error: 794.6956\n",
      "Epoch 140/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 860.9445 - mean_squared_error: 793.2449\n",
      "Epoch 141/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 863.6828 - mean_squared_error: 796.1412\n",
      "Epoch 142/200\n",
      "49599/49599 [==============================] - 0s 5us/step - loss: 858.4254 - mean_squared_error: 791.0609\n",
      "Epoch 143/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 861.7502 - mean_squared_error: 794.5578\n",
      "Epoch 144/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 859.1995 - mean_squared_error: 792.1573\n",
      "Epoch 145/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 858.8425 - mean_squared_error: 791.9775\n",
      "Epoch 146/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 859.9952 - mean_squared_error: 793.2971\n",
      "Epoch 147/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 858.6806 - mean_squared_error: 792.1469\n",
      "Epoch 148/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 859.8588 - mean_squared_error: 793.4935\n",
      "Epoch 149/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 858.3460 - mean_squared_error: 792.1190\n",
      "Epoch 150/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 856.1926 - mean_squared_error: 790.1523\n",
      "Epoch 151/200\n",
      "49599/49599 [==============================] - 0s 6us/step - loss: 856.6607 - mean_squared_error: 790.7773\n",
      "Epoch 152/200\n",
      "49599/49599 [==============================] - 0s 7us/step - loss: 854.3280 - mean_squared_error: 788.6005\n",
      "Epoch 153/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 860.1748 - mean_squared_error: 794.6168\n",
      "Epoch 154/200\n",
      "49599/49599 [==============================] - 1s 17us/step - loss: 857.0884 - mean_squared_error: 791.6856\n",
      "Epoch 155/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 856.1784 - mean_squared_error: 790.9116\n",
      "Epoch 156/200\n",
      "49599/49599 [==============================] - 1s 12us/step - loss: 855.4021 - mean_squared_error: 790.3022\n",
      "Epoch 157/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 859.0478 - mean_squared_error: 794.0814\n",
      "Epoch 158/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 854.9217 - mean_squared_error: 790.1122\n",
      "Epoch 159/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 855.2252 - mean_squared_error: 790.5499\n",
      "Epoch 160/200\n",
      "49599/49599 [==============================] - 1s 12us/step - loss: 854.2852 - mean_squared_error: 789.7742\n",
      "Epoch 161/200\n",
      "49599/49599 [==============================] - 1s 13us/step - loss: 855.4313 - mean_squared_error: 791.0437\n",
      "Epoch 162/200\n",
      "49599/49599 [==============================] - 1s 12us/step - loss: 854.7595 - mean_squared_error: 790.5324\n",
      "Epoch 163/200\n",
      "49599/49599 [==============================] - 1s 12us/step - loss: 853.8703 - mean_squared_error: 789.7686\n",
      "Epoch 164/200\n",
      "49599/49599 [==============================] - 1s 14us/step - loss: 855.1483 - mean_squared_error: 791.1851\n",
      "Epoch 165/200\n",
      "49599/49599 [==============================] - 1s 16us/step - loss: 854.6477 - mean_squared_error: 790.8066\n",
      "Epoch 166/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 849.2593 - mean_squared_error: 785.5510\n",
      "Epoch 167/200\n",
      "49599/49599 [==============================] - 1s 14us/step - loss: 853.2952 - mean_squared_error: 789.7195\n",
      "Epoch 168/200\n",
      "49599/49599 [==============================] - 1s 12us/step - loss: 850.9406 - mean_squared_error: 787.4934\n",
      "Epoch 169/200\n",
      "49599/49599 [==============================] - 1s 12us/step - loss: 849.5082 - mean_squared_error: 786.1813\n",
      "Epoch 170/200\n",
      "49599/49599 [==============================] - 1s 14us/step - loss: 849.6035 - mean_squared_error: 786.4110\n",
      "Epoch 171/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 848.5323 - mean_squared_error: 785.4681\n",
      "Epoch 172/200\n",
      "49599/49599 [==============================] - 1s 13us/step - loss: 847.3158 - mean_squared_error: 784.3746\n",
      "Epoch 173/200\n",
      "49599/49599 [==============================] - 0s 10us/step - loss: 851.9864 - mean_squared_error: 789.2018\n",
      "Epoch 174/200\n",
      "49599/49599 [==============================] - 0s 10us/step - loss: 845.0976 - mean_squared_error: 782.4521\n",
      "Epoch 175/200\n",
      "49599/49599 [==============================] - 1s 10us/step - loss: 851.6387 - mean_squared_error: 789.1188\n",
      "Epoch 176/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 844.4142 - mean_squared_error: 782.0082\n",
      "Epoch 177/200\n",
      "49599/49599 [==============================] - 1s 10us/step - loss: 849.5860 - mean_squared_error: 787.3036\n",
      "Epoch 178/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 849.5690 - mean_squared_error: 787.4253\n",
      "Epoch 179/200\n",
      "49599/49599 [==============================] - 1s 12us/step - loss: 844.6584 - mean_squared_error: 782.6312\n",
      "Epoch 180/200\n",
      "49599/49599 [==============================] - 0s 10us/step - loss: 851.1401 - mean_squared_error: 789.2489\n",
      "Epoch 181/200\n",
      "49599/49599 [==============================] - 0s 10us/step - loss: 846.2083 - mean_squared_error: 784.4284\n",
      "Epoch 182/200\n",
      "49599/49599 [==============================] - 0s 10us/step - loss: 844.2744 - mean_squared_error: 782.6137\n",
      "Epoch 183/200\n",
      "49599/49599 [==============================] - 0s 10us/step - loss: 844.9051 - mean_squared_error: 783.3643\n",
      "Epoch 184/200\n",
      "49599/49599 [==============================] - 0s 10us/step - loss: 843.5714 - mean_squared_error: 782.1470\n",
      "Epoch 185/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 842.2258 - mean_squared_error: 780.8994\n",
      "Epoch 186/200\n",
      "49599/49599 [==============================] - 1s 13us/step - loss: 845.1340 - mean_squared_error: 783.9483\n",
      "Epoch 187/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 846.3087 - mean_squared_error: 785.2448\n",
      "Epoch 188/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 842.9334 - mean_squared_error: 781.9794\n",
      "Epoch 189/200\n",
      "49599/49599 [==============================] - 1s 14us/step - loss: 844.7930 - mean_squared_error: 783.9615\n",
      "Epoch 190/200\n",
      "49599/49599 [==============================] - 1s 10us/step - loss: 841.6078 - mean_squared_error: 780.8886\n",
      "Epoch 191/200\n",
      "49599/49599 [==============================] - 1s 10us/step - loss: 842.6198 - mean_squared_error: 781.9985\n",
      "Epoch 192/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 838.2039 - mean_squared_error: 777.7341\n",
      "Epoch 193/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 845.6525 - mean_squared_error: 785.2684\n",
      "Epoch 194/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 837.1618 - mean_squared_error: 776.8871\n",
      "Epoch 195/200\n",
      "49599/49599 [==============================] - 1s 15us/step - loss: 848.0264 - mean_squared_error: 787.8763\n",
      "Epoch 196/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 840.2887 - mean_squared_error: 780.2407\n",
      "Epoch 197/200\n",
      "49599/49599 [==============================] - 0s 9us/step - loss: 839.7350 - mean_squared_error: 779.7939\n",
      "Epoch 198/200\n",
      "49599/49599 [==============================] - 1s 14us/step - loss: 837.2247 - mean_squared_error: 777.3948\n",
      "Epoch 199/200\n",
      "49599/49599 [==============================] - 1s 13us/step - loss: 836.9345 - mean_squared_error: 777.2060\n",
      "Epoch 200/200\n",
      "49599/49599 [==============================] - 1s 11us/step - loss: 842.2981 - mean_squared_error: 782.6701\n",
      "259/259 [==============================] - 0s 768us/step\n",
      "[[34.03734039]]\n",
      "Best Score\n",
      "34.037340385825395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model for dataset 2 to disk\n"
     ]
    }
   ],
   "source": [
    "#datasets = [1, 2, 3, 4]\n",
    "datasets = [2]\n",
    "iterations = 1\n",
    "\n",
    "window_sizes = {1:24,2:17,3:24,4:17}\n",
    "strides = {1:1,2:1,3:1,4:1}\n",
    "max_ruls = {1:129, 2:139, 3:129, 4:139}\n",
    "\n",
    "scores ={1:[], 2:[], 3:[], 4:[]}\n",
    "models = {1:RULmodel_SN_1}\n",
    "\n",
    "\n",
    "#Create tunable model\n",
    "\n",
    "num_features = len(selected_features)\n",
    "\n",
    "shape = len(selected_features)*window_size\n",
    "#file = open(\"ResultsBestModelAllDatasetsSingleSet.csv\", \"w\")\n",
    "#csvfile = csv.writer(file, lineterminator='\\n')\n",
    "\n",
    "tempScoresRMSE = []\n",
    "tempScoresRHS = []\n",
    "tempTime = []\n",
    "\n",
    "#Run experiments\n",
    "for i in datasets:\n",
    "    \n",
    "    min_rmse = 1000\n",
    "    bestModel = None\n",
    "    bestIndex = 0\n",
    "    \n",
    "    print(\"Working on dataset \" + str(i))\n",
    "        \n",
    "    tempScoresRMSE = np.zeros((iterations,1))\n",
    "    tempScoresRHS = np.zeros((iterations,1))\n",
    "    tempTime = np.zeros((iterations,1))\n",
    "        \n",
    "    input_shape = window_sizes[i]*num_features #For simple ANN\n",
    "\n",
    "    for j in range(iterations):\n",
    "\n",
    "        #Create keras model\n",
    "        print(\"Iteration \"+str(j+1))\n",
    "        #file.write(\"Iteration \"+str(j+1)+'\\n\\n')\n",
    "\n",
    "        model = get_compiled_model(input_shape, model_type='ann')\n",
    "        tModel = SequenceTunableModelRegression('ModelRUL_SN_1', model, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "\n",
    "        #Load data\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        tModel.data_handler.change_dataset(i)\n",
    "        tModel.data_handler.sequence_length = window_sizes[i]\n",
    "        tModel.data_handler.sequence_stride = strides[i]\n",
    "        tModel.data_handler.max_rul = max_ruls[i]\n",
    "\n",
    "        tModel.data_handler.data_scaler = None\n",
    "        tModel.data_scaler = min_max_scaler\n",
    "\n",
    "        tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "        #tModel.data_handler.print_data()\n",
    "        #tModel.print_data()\n",
    "\n",
    "        #Train model\n",
    "        tModel.epochs = 200\n",
    "\n",
    "        tModel.train_model(verbose=1)\n",
    "        tModel.evaluate_model(['rhs', 'rmse'], round=2)\n",
    "\n",
    "        cScores = tModel.scores\n",
    "        rmse = math.sqrt(cScores['score_1'])\n",
    "        rmse2 = cScores['rmse']\n",
    "        rhs = cScores['rhs']\n",
    "        time = tModel.train_time\n",
    "\n",
    "        if rmse2 < min_rmse:\n",
    "            best_model_weights = tModel.model.get_weights()\n",
    "            #bestModel.set_weights(tModel.model.get_weights())\n",
    "            bestIndex = j\n",
    "            min_rmse = rmse2\n",
    "\n",
    "        tempScoresRMSE[j] = rmse2\n",
    "        tempScoresRHS[j] = rhs\n",
    "        tempTime[j] = time\n",
    "\n",
    "    print(tempScoresRMSE)\n",
    "    print('Best Score')\n",
    "    print(min_rmse)\n",
    "    \n",
    "    #save best model to file\n",
    "    #serialize model to JSON\n",
    "\n",
    "    #print(best_model_weights)\n",
    "    model = get_compiled_model(input_shape, model_type='ann')\n",
    "    bestModel = SequenceTunableModelRegression('ModelRUL_SN_1', model, lib_type='keras', data_handler=dHandler_cmaps).model\n",
    "    bestModel.set_weights(best_model_weights)\n",
    "    model_json = bestModel.to_json()\n",
    "    with open(\"bestRULModel_dataset_\"+str(i)+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    bestModel.save_weights(\"bestRULModel_dataset_\"+str(i)+\".h5\")\n",
    "    print(\"Saved best model for dataset \"+str(i)+\" to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Loading data for the first time\n",
      "Reloading data due to parameter change\n",
      "Loading data for dataset 2 with window_size of 17, stride of 1 and maxRUL of 139. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "Description for model: ModelRUL_SN_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 20)                4780      \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 5,221\n",
      "Trainable params: 5,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('bestRULModel_dataset_2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"bestRULModel_dataset_2.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "#Shared parameters for the models\n",
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "#Create and compile the models\n",
    "#nFeatures = len(selected_features)\n",
    "#shapeSN = nFeatures*windowSize\n",
    "#modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "loaded_model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "#min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "tModel = SequenceTunableModelRegression('ModelRUL_SN_1', loaded_model, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "\n",
    "i = 2\n",
    "\n",
    "tModel.data_handler.change_dataset(i)\n",
    "tModel.data_handler.sequence_length = window_sizes[i]\n",
    "tModel.data_handler.sequence_stride = strides[i]\n",
    "tModel.data_handler.max_rul = max_ruls[i]\n",
    "\n",
    "tModel.data_handler.data_scaler = None\n",
    "tModel.data_scaler = min_max_scaler\n",
    "\n",
    "tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "#tModel.print_data()\n",
    "#print(tModel.model.get_weights())\n",
    "tModel.get_model_description()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 0s 512us/step\n",
      "scores\n",
      "{'loss': 1221.6244099149374, 'score_1': 1162.0175140263032, 'rhs': 159.51125585952417, 'rmse': 34.037340385825395}\n",
      "{'loss': 1221.6244099149374, 'score_1': 1162.0175140263032, 'rhs': 159.51125585952417, 'rmse': 34.037340385825395}\n",
      "RMSE: 34.088377990545446\n",
      "RMSE2: 34.037340385825395\n",
      "RHS: 159.51125585952417\n",
      "Time : None seconds\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "tModel.evaluate_model(['rhs', 'rmse'], round=2)\n",
    "print(\"scores\")\n",
    "\n",
    "#print(tModel.y_pred)\n",
    "\n",
    "cScores = tModel.scores\n",
    "print(cScores)\n",
    "rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.train_time\n",
    "\n",
    "print(cScores)\n",
    "print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
